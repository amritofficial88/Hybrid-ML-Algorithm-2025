{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "version": "3.6.3"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd "
      ],
      "metadata": {
        "_cell_guid": "170f0fb3-b5da-4a9b-870a-0365b4bc8f30",
        "_uuid": "a31348a5eba01332c755b5d244ff9d8a5f1d3ee7",
        "scrolled": true,
        "id": "fjrbwJyi7Jps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "QVZHCt0b4giz",
        "outputId": "5df8fed1-a29f-4a8a-d888-a880fa3c6c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-692557ae-6781-444f-9a63-bcfd06435da5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-692557ae-6781-444f-9a63-bcfd06435da5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving colon - labled-1 C.csv to colon - labled-1 C (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['colon - labled-1 C.csv']))"
      ],
      "metadata": {
        "id": "nEghRXyS4me8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = df.Class\n",
        "X = df.drop('Class', axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)\n",
        "print(\"\\nX_train:\\n\")\n",
        "print(X_train.head())\n",
        "print(X_train.shape)\n",
        "\n",
        "print(\"\\nX_test:\\n\")\n",
        "print(X_test.head())\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_fvqxA1dW_f",
        "outputId": "7aa01dbb-0307-4609-ec2c-6ee2327d8f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "X_train:\n",
            "\n",
            "    Unnamed: 0      H55933     R39465    R39465_     R85482     U14973  \\\n",
            "59          60   6730.6250  3472.1250  2559.4624  2624.6892  1596.2179   \n",
            "38          39   3656.7837  5082.8570  4101.9175  1365.7000  1980.2333   \n",
            "42          43  11447.6310  3529.1272  2920.8413  5445.8623  2699.2620   \n",
            "7            8   4028.7100  3156.1592  2870.2550  4417.5913  1854.1060   \n",
            "61          62   7472.0100  3653.9340  2728.2163  3494.4805  2404.6655   \n",
            "\n",
            "       R02593     T51496     H80240     T65938  ...     X67699     R70790  \\\n",
            "59  4372.7890  3798.5261  1026.4775  3512.3337  ...  254.86548  119.96250   \n",
            "38  4883.8930  2925.7375  2061.4126  1482.9713  ...  176.50119   91.00375   \n",
            "42  6637.8145  4903.8965  3411.6025  2534.9038  ...  372.16190   60.37125   \n",
            "7   2828.3037  1427.5262  3390.7063  4373.0440  ...  116.19405   46.67375   \n",
            "61  5791.6070  2876.4211  2150.9587  3767.0024  ...  178.94643   63.63500   \n",
            "\n",
            "       L11706     T90549     D17390     M33210     H18490     H40891  \\\n",
            "59  111.60375  166.75500  130.45500  124.25357   96.46500  133.52126   \n",
            "38  267.03625  133.94875   46.74250  120.30119   11.00625   15.99000   \n",
            "42  232.72874  214.44624  372.51750  463.85240  317.15375  334.36874   \n",
            "7   172.78876   51.82375   97.85500   98.98214   24.19625   29.76625   \n",
            "61  437.65250  178.27250  153.84875  269.43690   67.86250   77.21500   \n",
            "\n",
            "       R77780     T49647  \n",
            "59   93.09875    7.43250  \n",
            "38   21.34375   30.74375  \n",
            "42  176.56750  126.82625  \n",
            "7    44.37625   52.29000  \n",
            "61   49.86250   39.63125  \n",
            "\n",
            "[5 rows x 2001 columns]\n",
            "(49, 2001)\n",
            "\n",
            "X_test:\n",
            "\n",
            "    Unnamed: 0     H55933     R39465    R39465_     R85482     U14973  \\\n",
            "18          19  5382.3940  3848.4430  3372.4888  4444.5660  2464.9023   \n",
            "46          47  6951.3540  5565.7773  4480.7850  3667.6465  4278.6167   \n",
            "37          38  4201.5073  2425.6272  2228.8174  1503.6053  3804.5332   \n",
            "52          53  7666.6750  6409.7390  6489.8640  2451.1180  4176.2120   \n",
            "50          51  6870.3223  4751.7610  4102.3450  3182.0037  3193.6594   \n",
            "\n",
            "       R02593     T51496     H80240     T65938  ...      X67699     R70790  \\\n",
            "18  1304.5571  1062.6975  2903.3250  4866.8086  ...   80.970240   29.93500   \n",
            "46  7568.9287  6299.3613  5174.0913  4038.1850  ...  192.760710  107.79500   \n",
            "37  3591.2500  4028.5886  2794.0850  2683.0250  ...   49.663094  117.72250   \n",
            "52  4654.6357  2321.5225  3520.3162  4477.4510  ...  109.186900   32.20375   \n",
            "50  7264.9927  3777.5024  2669.4326  4191.8900  ...  309.905940   35.18250   \n",
            "\n",
            "       L11706     T90549     D17390      M33210    H18490     H40891  \\\n",
            "18  155.76750   50.89500   43.65750  118.461900   22.0475   62.68625   \n",
            "46  624.72750  155.82250  173.10500  297.486900  228.8050  140.87125   \n",
            "37  487.72750   43.51625   73.06625   64.540474   47.5775   46.59750   \n",
            "52  601.84750  117.00375   62.32000  167.308330   13.2675   52.09250   \n",
            "50  153.17375   66.53125  149.97750   65.961910   47.6850  101.89875   \n",
            "\n",
            "      R77780    T49647  \n",
            "18   6.00000  25.10500  \n",
            "46  66.44375  73.62000  \n",
            "37  13.27375  97.86750  \n",
            "52  47.71750  30.42000  \n",
            "50  64.73375  34.24875  \n",
            "\n",
            "[5 rows x 2001 columns]\n",
            "(13, 2001)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mrmr_selection\n",
        "from mrmr import mrmr_classif\n",
        "from sklearn.datasets import make_classification\n",
        "selected_features = mrmr_classif(X, y, K = 500)\n",
        "print(selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iECUl316bPvG",
        "outputId": "5bd7653e-2e50-4d17-e589-b848f5ab9161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mrmr_selection in /usr/local/lib/python3.8/dist-packages (0.2.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from mrmr_selection) (2.11.3)\n",
            "Requirement already satisfied: category-encoders in /usr/local/lib/python3.8/dist-packages (from mrmr_selection) (2.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from mrmr_selection) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.8/dist-packages (from mrmr_selection) (1.21.6)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (from mrmr_selection) (0.0.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from mrmr_selection) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from mrmr_selection) (1.2.0)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from mrmr_selection) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->mrmr_selection) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->mrmr_selection) (2.8.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from category-encoders->mrmr_selection) (1.0.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from category-encoders->mrmr_selection) (0.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from category-encoders->mrmr_selection) (0.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->mrmr_selection) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.1->category-encoders->mrmr_selection) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category-encoders->mrmr_selection) (3.1.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [03:55<00:00,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['M63391', 'D13641', 'J02854', 'M76378__', 'H55916', 'Z50753', 'H08393', 'R87126', 'M76378', 'T62947', 'M76378_', 'X63629', 'T71025', 'T92451', 'J05032', 'R84411', 'R80427', 'U25138', 'X12671', 'T47377', 'H43887', 'T56604', 'H64489', 'M26697', 'M82919', 'H40095', 'M36634', 'T57468', 'X86693', 'M22382', 'U09587', 'X12369', 'T95018', 'H23544', 'T60155', 'T57619', 'H06524', 'X55715', 'Z24727', 'R08183', 'M80815', 'X14958', 'R78934', 'D43950', 'H55758', 'U19969', 'H67764', 'X70326', 'T60778', 'U09564', 'L07648', 'X12466', 'T67077', 'T51261', 'H40560', 'M64110', 'L11706', 'R36977', 'R54097', 'H77597', 'H05803', 'L05144', 'T58861', 'T83368', 'R62549', 'R44301', 'M26383', 'T59878', 'U14631', 'T51023', 'T51529', 'X56597', 'R67358', 'D00860', 'R15447', 'U32519', 'T86473', 'U01038', 'T48804', 'M91463', 'T52185', 'Z49269_', 'T51571', 'X74295', 'U30825', 'X83301', 'D29808', 'U17899', 'R60877', 'U22055', 'X54942', 'Z49269', 'T90350', 'T61609', 'T61661_', 'T79152', 'D31716', 'T70062', 'H17434', 'M36981', 'T94350', 'R64115', 'X15880', 'H65355', 'R10066', 'D42047', 'M87789', 'T63370', 'M15841', 'D31885', 'H20426', 'X16356', 'X87159', 'L12723', 'U14971', 'U31525', 'U21090', 'M94203', 'T98555', 'H70425', 'H41129', 'D38551', 'T51534', 'M34344', 'X15882', 'R42501', 'H24030', 'L10284', 'D26129', 'U26312', 'T49732', 'M96839', 'T89666', 'X54941', 'D13315_', 'T51858', 'J00231', 'T62972', 'M96233', 'M58050', 'R44418', 'H40137', 'M34175__', 'T56940', 'H72234', 'T51493', 'R08021', 'T61661', 'T51539', 'R97912', 'R46753', 'Z48541', 'T96873', 'T86749', 'T95048', 'T72938', 'T57483', 'D16431', 'M83667', 'Z11502', 'R34698', 'M28128', 'U04953', 'M35531', 'T63133', 'H89087', 'U02493', 'Z25521', 'M26252', 'R48303', 'X06614', 'U05040', 'D21261', 'H11084', 'R42127', 'R75843', 'M28882', 'X75208', 'T50797', 'X15183', 'T47144', 'X68277', 'H40269', 'M18216', 'L08069', 'T90280', 'X53586', 'M94630', 'R99907', 'T72863', 'X74795', 'H78386', 'R81170', 'M69135', 'L28010', 'X68314', 'M19045', 'M92287', 'R41873', 'R44884', 'T40578', 'T40454', 'X60489', 'X06614_', 'T72175', 'R33367', 'D59253', 'X72727', 'T68848', 'T94993', 'Y00345', 'T50321', 'H01346', 'J04102', 'H87344', 'J04621', 'M16937', 'R42244', 'T67406', 'D25217', 'R44770', 'X74330', 'M88279', 'T41204', 'D63874', 'D14662', 'T71001', 'D00596', 'R34876', 'T47383', 'R16156', 'M94556', 'X68688', 'R88740', 'H25136', 'R11485', 'K03460', 'M86553', 'H20709', 'R50158', 'H17646', 'X89986', 'T55248', 'X12496', 'M37583', 'T57633', 'R37428', 'X55187', 'X07290', 'R93738', 'T54276', 'M92843', 'R01182', 'D29641', 'D14520', 'D00763', 'T72889', 'R65697', 'T69748', 'D15049', 'R23889', 'D00762', 'L06132', 'M64445', 'M31303', 'L38503', 'control4', 'control5', 'L19437', 'control6', 'U37012', 'control7', 'H65823', 'T56244', 'M34175_', 'T53549', 'X66839', 'M76558', 'X01060', 'T56690', 'R49565', 'M29065', 'U10324', 'H05899', 'T72879', 'U07664', 'M34175', 'T52015', 'H79136', 'H62828', 'L03840', 'R98842', 'H24401', 'R40717_', 'J03210', 'X55362', 'T48904', 'T63496', 'J04813', 'M84721', 'M86737', 'X87342', 'M26683', 'M28373', 'T65790', 'T63591', 'R96357', 'T84049', 'M22490', 'L09604', 'control8', 'X73902', 'X67155', 'R39465_', 'T69446', 'M94132', 'T47584', 'T57780', 'L24203', 'X13482', 'U31215', 'T60437', 'Y00264', 'X07767', 'M65028', 'R86975', 'M81637', 'D13627', 'R01124', 'T51558', 'H20819', 'U24166', 'R20554', 'R56401', 'X69141', 'control9', 'R80612', 'M14200', 'X62153', 'H87473', 'H61410', 'U28686', 'M85289', 'U21049', 'R54422', 'T57630', 'H20512', 'R28373', 'H22579_', 'T65003', 'R22197', 'T84481', 'R67999', 'control10', 'X65873', 'H65182', 'M83751', 'M35878', 'M93651', 'T53889', 'T52642', 'R54941', 'H16991', 'M65105', 'L38951', 'H81068', 'T70058', 'control11', 'R56399', 'X57351', 'U12255_', 'M23115', 'M86752', 'D14665', 'M23419_', 'H64807', 'U34074', 'M59040', 'X81817', 'T51849', 'M86400', 'R41866', 'R71585', 'D13315', 'X82103', 'T93094', 'U29092', 'U06698', 'R40717', 'H38185', 'D16294', 'X70944', 'T64012', 'T61602', 'L41559', 'J04794', 'M64231', 'R49416', 'R78927', 'Z17240', 'X16354', 'T50334_', 'L37936', 'X81372', 'D14663', 'R43914', 'T78104', 'X72018', 'T58645', 'X89985', 'T54364', 'T40645', 'H81558', 'R73660', 'R52081', 'T54341', 'T51613', 'T47645', 'J04026', 'T80178', 'T65938', 'Y00971', 'U07695_', 'R45529', 'D13665', 'R70030', 'T53694', 'R44052', 'T65758', 'T49423', 'M14200_', 'X51417', 'T47719', 'J00073', 'U10362', 'T94579', 'T65740', 'D16469', 'R21547', 'M88108', 'U07695__', 'M97676', 'T48102', 'T92259', 'X64229', 'J03569', 'D14812', 'L27476', 'H45977', 'H06245', 'H86060', 'M90516', 'T57780_', 'R27369', 'H72965', 'R49459', 'T57686', 'T60318', 'R39209', 'M22632', 'U26710', 'K02268', 'U07695', 'M81933', 'Z18948', 'M77698', 'H73908', 'U05291', 'M21339', 'D55673', 'R37464', 'H39654', 'T49941', 'U26401', 'T71574', 'M63239', 'H23098', 'D43947', 'D17400', 'T72503', 'T73092', 'U12255', 'L33930', 'U37673_', 'D00761', 'R67343', 'L13385', 'H87135', 'T53396_', 'T58731', 'Y00711', 'R59202', 'R43913', 'T62220', 'J03040', 'X69295', 'L05485', 'X73882', 'R59583', 'R62945']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "X_mrmr = X_train[selected_features]\n",
        "print(X_mrmr)\n",
        "print(X_mrmr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmNHhAPCSn5w",
        "outputId": "5dcde0f9-75cd-46b5-de2a-0cee45d10e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        M63391     D13641      J02854    M76378__     H55916      Z50753  \\\n",
            "59  1817.94000  163.35500   887.69500   373.77124   58.37375  919.772640   \n",
            "38  2689.20500  115.64000  1214.46370  1109.59250   18.07500  471.222630   \n",
            "42  5832.31740  409.52000  2008.51370  1550.91130  171.30500  828.645260   \n",
            "7   3886.99240   42.21000   541.53250  1781.31750   33.81625  388.407140   \n",
            "61  2699.19240  124.87750   953.95374   549.09500   42.14000  337.372620   \n",
            "33   779.63873  262.99250   170.10374   167.89125  177.16500  237.791670   \n",
            "0    552.65875   85.31500   309.49374   389.76500  113.10000  282.278560   \n",
            "40   335.69000   58.37500   182.51875    84.99375  141.97750   96.270240   \n",
            "22   182.00125  157.11750    16.04250    93.28375   18.17875   75.367860   \n",
            "60   272.92874  113.26750    58.47750    52.95500   75.13125  198.930950   \n",
            "8    404.31876  114.61875   183.70625   380.59750  178.56500  161.103580   \n",
            "23   163.60875   38.28375    69.13250   140.63000   21.49000  210.222630   \n",
            "34   505.99000   86.83500   181.66500   287.45126  146.32124  156.995240   \n",
            "9   4322.87900  301.47375   774.27875  2514.76760   64.13750  445.744050   \n",
            "43   846.97500  891.84250   228.12000   275.65250  196.16500  392.741670   \n",
            "39   500.42500  286.07250   165.18500    39.38125   97.52875  236.266660   \n",
            "20   188.36626  165.60750    81.27125   185.09750  135.34875  325.470250   \n",
            "5   2030.87740   44.65875   325.04500  1386.82250   35.55500  196.595250   \n",
            "28   448.47375  664.26373   413.35500   281.86000  272.97500  340.164280   \n",
            "31   812.82120  213.29500   111.43875   306.00250   32.75250  149.711900   \n",
            "56   657.41000   32.78250   374.20000   107.52375  274.79500  147.258330   \n",
            "15   183.62125   60.13625   277.54376   314.35250   62.68750  208.614290   \n",
            "53  3134.93870  129.05624  1343.42110   935.20374  160.75375  357.827400   \n",
            "32   287.17374  149.10750    43.59250   264.90375   63.95875  150.567860   \n",
            "36   250.28125  437.22876   401.69000   180.72874  156.71875  246.995240   \n",
            "35   219.72000  135.69500    30.19750   110.49750  114.33375   87.564285   \n",
            "27   329.86874  333.84125   178.57375   215.50125  225.21875  246.923810   \n",
            "41  1765.18500   81.37375   480.35626   449.39500    8.15000  686.633300   \n",
            "11  3552.98400  111.00875  2221.75120  3321.14870  136.14750  477.913100   \n",
            "44  2517.47120  462.47125  1494.58750   749.40750  212.16500  615.353600   \n",
            "30   471.47876  268.16376   664.96250   566.89624  206.53876  274.546420   \n",
            "14   636.02374   85.86500   282.37750   543.47000  108.77000  199.572620   \n",
            "10   416.17126  649.23880    61.53000   333.17874   78.15250  526.650000   \n",
            "57   175.22874   69.23500    88.56625    42.74000  175.82124  143.870240   \n",
            "54   221.18375  142.64500   148.65875    42.12875   41.43625  231.797620   \n",
            "49  4642.06350  178.75626  2202.90380  1063.71500  141.72250  294.604770   \n",
            "48  1627.27000  134.48500   590.41376   322.62875   60.39125  334.123800   \n",
            "16   185.32250   87.81625    49.02125   111.71000   43.17250  180.897610   \n",
            "45   867.55000  381.04874   103.12750   288.40000  252.37875  422.790470   \n",
            "12   632.74630  165.05125   244.73750   494.24750  307.12250  260.173800   \n",
            "3    987.79877   26.45375   973.16876   723.40125  126.10125  321.620240   \n",
            "55  2787.04250  102.72500   697.32750   733.76874   33.86750  341.264280   \n",
            "19  3034.68750   81.65875   296.63126  1560.54750   12.20000  351.350000   \n",
            "2    137.97125   40.35875   333.62500   164.73250   74.45500  217.133330   \n",
            "25   103.42625  243.63250    85.42625   105.71625  143.81000  150.992860   \n",
            "13  1872.49130   77.29625  1236.29880  1491.04610   74.71125  319.444060   \n",
            "6    228.28625   96.95750   126.43000   154.05500  130.45625  195.650000   \n",
            "1   2314.94870  166.79875  1644.42610  1779.98750  106.00750  761.378540   \n",
            "51  1082.38120  224.17000    21.08000   339.10000  104.74375  305.238100   \n",
            "\n",
            "       H08393      R87126      M76378     T62947  ...      Y00711     R59202  \\\n",
            "59   59.61250   476.19500   697.11150   33.63125  ...   303.20000   28.41750   \n",
            "38   78.09500   437.01126  1723.44810   87.12750  ...    85.48875   92.26750   \n",
            "42   38.14625  2161.89750  1094.67310  147.95750  ...   618.76500  110.16625   \n",
            "7    45.74625   598.49750  1849.61730   43.55500  ...    96.41750   61.48875   \n",
            "61   82.04750   596.04500  1240.58460  154.01250  ...   317.80124  152.60750   \n",
            "33  127.94875   241.73875   472.14615  147.13750  ...   640.05630   55.16625   \n",
            "0    87.71000   624.42630   475.27884   74.53250  ...   345.50876   61.89500   \n",
            "40   50.67750    93.07750   196.51154   49.33250  ...   128.20876   26.12125   \n",
            "22   80.11875    79.30000   118.08269  176.40000  ...    69.82500   61.44500   \n",
            "60   63.32125   103.10375   191.33846  117.42875  ...   352.82500   49.74500   \n",
            "8   161.76375   170.11375   503.65192  295.19750  ...   592.16000   45.38875   \n",
            "23    9.76875   229.04500   212.96153   17.81750  ...    46.48500   37.79250   \n",
            "34   90.83250   214.05750   364.57886  107.95375  ...   431.92624   23.76625   \n",
            "9    63.85250   906.42880  2510.98460  108.63500  ...   112.91000  108.77875   \n",
            "43  160.85625   302.89500   541.35190  275.35750  ...   764.19620   75.17750   \n",
            "39  182.19750   201.14750   226.80000  235.14500  ...   882.99000   84.74500   \n",
            "20   89.76000   489.83374   271.71155   98.69875  ...   476.08624   53.39500   \n",
            "5    56.02750   387.24250  1453.34420   70.93000  ...    57.53625   78.91125   \n",
            "28  159.58624   286.00250   473.99808  155.33624  ...   345.59500   58.11750   \n",
            "31  107.41125   175.81500   663.10767   72.17125  ...   203.25125   41.00250   \n",
            "56   63.61250   248.54124   442.29422   52.68875  ...    98.96375   76.94250   \n",
            "15   61.59875   418.39874   608.62690   83.50500  ...   110.72750   54.58500   \n",
            "53   80.68375   580.72750  2307.57500  142.64000  ...   170.95125  167.98250   \n",
            "32  112.94125   147.20000   436.23846  139.58500  ...   505.62625   28.44500   \n",
            "36  109.72125   280.29126   362.34040  114.17875  ...   439.84125   14.14625   \n",
            "35  152.01500    60.51250   287.39807  162.59000  ...   436.94750   38.90250   \n",
            "27  220.04375   254.69376   289.83078  137.89500  ...   753.21500   66.20875   \n",
            "41  121.20250   543.28625  1263.40380  100.74500  ...   188.29000  153.67250   \n",
            "11   68.18125  1747.85500  2679.89040  152.76500  ...   493.27625  103.65250   \n",
            "44   89.42500  1051.74380  1811.18850  192.99500  ...   687.38000  191.67625   \n",
            "30   93.69875   261.01126   739.27310  290.05875  ...   531.58875   82.09875   \n",
            "14  153.99625   449.80374   633.22310  190.49625  ...    40.57250   78.92000   \n",
            "10  326.66750   365.39374   334.96540  171.93625  ...  2454.72880  152.55250   \n",
            "57   47.65000   114.88000   134.11923   56.25875  ...   190.72500   18.78250   \n",
            "54   48.45250   153.23000   105.08462   18.16250  ...   320.25876   42.55375   \n",
            "49   66.94000  1777.96620  2570.95970   75.92750  ...   335.79126   94.36625   \n",
            "48   57.80250   625.89750  1002.08270   27.87000  ...   285.57250   46.16625   \n",
            "16   61.74000   193.85000   194.14809  109.64250  ...   168.31750   64.84875   \n",
            "45  337.64500   443.05500   453.28845  244.12250  ...   133.98375  120.63625   \n",
            "12  152.88000   304.48874   528.86346   72.15875  ...    75.56000   83.38125   \n",
            "3    27.58000   660.61000   576.64040   46.42750  ...   138.96875   73.46375   \n",
            "55   75.66875   371.53625  1746.38090  123.63000  ...    82.26875   83.29000   \n",
            "19   41.88125   760.44500  1605.61730   82.28625  ...    90.27625   67.63500   \n",
            "2    20.73500   338.46000   209.21922   33.96000  ...   108.18500   29.54250   \n",
            "25   71.58250   102.50750   149.65192   53.75750  ...   558.96875   15.51750   \n",
            "13   32.11250  1231.10620  1422.48270   79.43750  ...    99.68375   82.42250   \n",
            "6    79.39125   149.52250   214.58269   88.92125  ...   467.49124   32.03000   \n",
            "1    53.14750  1342.96750  1648.45960   66.07000  ...   754.86880   54.72625   \n",
            "51  375.80750   356.83000   527.05770  259.76250  ...   171.39250  144.99625   \n",
            "\n",
            "        R43913      T62220      J03040     X69295      L05485      X73882  \\\n",
            "59   373.61250  2595.43500  1381.68500  123.17375  168.045240   65.066666   \n",
            "38   176.47375  2547.32740   916.15875   24.84500  190.565480   50.367860   \n",
            "42   872.90375  3036.15750  1701.73000   74.77375  209.948800   32.239285   \n",
            "7    209.40125   786.10126   852.85876   79.49125  118.065480   19.019049   \n",
            "61   385.62250  1911.40120  1176.87870  125.59500  149.433330   12.213095   \n",
            "33   295.10250  1346.93370  2614.38870  138.79250  227.002380   45.591667   \n",
            "0    509.20500  1582.03500   771.33124  108.68875  144.970250   41.158333   \n",
            "40   186.23875  1485.52000   465.77000   36.31250  150.102390   16.744047   \n",
            "22   164.63875  1157.45000   625.86880   48.52000   63.335712   14.488095   \n",
            "60   408.51624   861.10626  1091.49370  112.65625   99.311905   26.720238   \n",
            "8    454.71750  3309.94240   477.80500   93.23875   94.721430    7.033333   \n",
            "23    64.68750   524.08750   110.47875   11.65000   25.534525   11.567857   \n",
            "34   417.14624  1879.32250  1025.24500  100.60875   72.316666   38.711906   \n",
            "9    281.96250  2423.36620  1087.02750   74.97750   99.694046   68.908330   \n",
            "43  1159.93630  1604.93380  1690.38000  244.47874   77.205956  123.057140   \n",
            "39   587.46000  1932.92000  1227.95120  102.69125  138.461900   80.920235   \n",
            "20   719.77500  2938.27880   735.34375  152.09125  158.960710   44.361904   \n",
            "5     66.39125   916.71250   280.61874   26.68250  103.552380   10.488095   \n",
            "28   934.83000  3425.46120  3040.23750  179.74500  123.953570  117.705950   \n",
            "31   383.73750   812.37620  2652.23400  112.86500   11.769048   31.126190   \n",
            "56   100.17625  1964.08370  2745.68630    8.14750   59.809525   11.085714   \n",
            "15   186.97500  1716.65380   165.94750   37.23500   31.594048    6.555953   \n",
            "53   171.74250  2675.09380   895.57370  117.72500  242.925000   48.270237   \n",
            "32   318.78876   781.05500   284.03375   67.31375   43.332140   57.747620   \n",
            "36   410.79500  1573.75240   904.70123   35.46250   59.195236    8.342857   \n",
            "35   248.10000   526.39624   537.79500   48.78875   45.363094   37.111904   \n",
            "27   538.00500  2059.73240  1378.58620  132.98875  207.854770   67.186905   \n",
            "41   356.63000  2069.18500   488.92624  159.47375  224.091670   49.860714   \n",
            "11   692.32500  2905.36870   760.13370   96.50000  166.766660   31.022620   \n",
            "44   701.13000  4026.87740  1696.64250  219.97750  428.042850   84.289280   \n",
            "30   460.09375  3636.58000  5519.81740  204.77374  154.047620   16.652382   \n",
            "14   365.11500  2443.97750  1214.39620  105.36000  147.144040   33.009525   \n",
            "10  1437.19500  1135.62740  2634.76250  204.57875   80.319046  113.691670   \n",
            "57   223.53000  1325.21250   497.52000   57.64125   68.372620   24.125000   \n",
            "54   318.47000  1180.19000  3111.50630  108.54750   83.755950   21.623810   \n",
            "49   341.17374  2133.67500  1831.02370   99.67125  232.373810   58.720238   \n",
            "48   326.08750  1472.83620  1003.44380   88.89875  145.190480   50.913094   \n",
            "16   287.28876   870.00370   753.95624   69.35625   56.048810   32.915478   \n",
            "45  1025.11250  1994.44620  1621.80500  247.77250  199.302380   86.022620   \n",
            "12   229.94624  1173.63240  1266.82390   89.94125  149.507140   33.065475   \n",
            "3    227.17625  3034.57130   201.79625   48.86875  260.235720   11.880952   \n",
            "55   195.68750  1533.62260  1245.29130  102.08250  102.184520   17.827381   \n",
            "19   148.94500   971.91626   551.18870   43.81000   94.866670   28.188095   \n",
            "2    126.45375   807.39374  1278.77880   39.97500  183.911900   24.025000   \n",
            "25   347.95000  1367.61250   926.12000   79.94625   79.450000   37.426190   \n",
            "13   201.35750  1912.94380   249.94000   63.27000  148.569050   32.853573   \n",
            "6    335.41376  1298.09250   494.27750  148.60000   45.577380   27.453571   \n",
            "1    534.20750  3218.32130  1042.66880  121.77000  194.090480   26.500000   \n",
            "51   549.48000  1814.33750   802.73750  175.26000  181.173810  118.152380   \n",
            "\n",
            "       R59583      R62945  \n",
            "59  163.65500   144.66000  \n",
            "38  102.89125    60.87750  \n",
            "42  357.01126   174.81625  \n",
            "7    57.88750    63.61125  \n",
            "61  203.23125   135.34375  \n",
            "33  368.92624    57.89375  \n",
            "0   113.69500    98.47250  \n",
            "40   69.76750    57.52875  \n",
            "22   35.56875     6.38250  \n",
            "60  235.47874   100.01500  \n",
            "8    82.09250    70.20375  \n",
            "23    7.32625    13.87375  \n",
            "34  174.96250   123.30375  \n",
            "9    86.20125    63.59875  \n",
            "43  467.65125  2586.04130  \n",
            "39  212.62500   212.33000  \n",
            "20  124.65250   108.38250  \n",
            "5    23.74000    26.41500  \n",
            "28  610.17126   191.23875  \n",
            "31  190.30000   247.84375  \n",
            "56   46.13750    45.56500  \n",
            "15  110.08625    16.16750  \n",
            "53  207.72250    46.12500  \n",
            "32  218.30000   322.49750  \n",
            "36  264.95874   124.58375  \n",
            "35  128.05125   356.67250  \n",
            "27  157.13500   165.08000  \n",
            "41  227.58000   427.41125  \n",
            "11  165.49625   117.54000  \n",
            "44  348.45750   565.25250  \n",
            "30  431.98500   203.92250  \n",
            "14  124.12375    88.87500  \n",
            "10  185.31375   216.68375  \n",
            "57   68.93250    53.29875  \n",
            "54  101.02625    80.68250  \n",
            "49  249.82625   154.55875  \n",
            "48  119.22875   317.49124  \n",
            "16   64.13625   104.82250  \n",
            "45  386.55750   921.68130  \n",
            "12  238.80000   103.80750  \n",
            "3   122.44375    97.97375  \n",
            "55  232.15125    68.31000  \n",
            "19   37.50125    26.13750  \n",
            "2   100.80625    51.04375  \n",
            "25  172.66250    92.96375  \n",
            "13  116.52500    25.21250  \n",
            "6    99.40375   277.92624  \n",
            "1    80.99125    76.40750  \n",
            "51  163.97250  1201.38880  \n",
            "\n",
            "[49 rows x 500 columns]\n",
            "(49, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "X_mrmr = X_mrmr.to_numpy()"
      ],
      "metadata": {
        "id": "q-YysNZElbiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = X_train[:,1:].reshape(X_train.shape[0],1,40, 50).astype('float32')\n",
        "X_train = trainX/255.0\n",
        "\n",
        "testX = X_test[:,1:].reshape(X_test.shape[0],1, 40, 50).astype('float32')\n",
        "X_test = testX/255.0\n",
        "\n",
        "mrmrX = X_mrmr[:,1:].reshape(X_mrmr.shape[0],1, 1, 499).astype('float32')\n",
        "X_mrmr = mrmrX/255.0"
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "fepRy7p_7Jpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "y_train = lb.fit_transform(y_train)\n",
        "y_test = lb.fit_transform(y_test)"
      ],
      "metadata": {
        "_cell_guid": "04bd1d50-0dee-409d-938e-678bcfb5a944",
        "_uuid": "ba10ccfb03cf8b78ad5b0672cb1cba91d3afb8f1",
        "scrolled": true,
        "id": "vZzIJgkg7Jpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=10)\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "for i in enumerate(kf.split(X)):\n",
        "    if i == 10:\n",
        "        num_classes = 10\n",
        "        epochs = 20\n",
        "        cnn_model = Sequential([\n",
        "            Conv2D(filters=32,kernel_size=3,activation='relu', input_shape=(1, 40, 50),data_format='channels_first'),\n",
        "            MaxPooling2D(pool_size=2) ,\n",
        "            Dropout(0.2),\n",
        "            Flatten(), \n",
        "            Dense(32,activation='relu'),\n",
        "            Dense(10,activation = 'softmax')\n",
        "        ])\n",
        "        \n",
        "        cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        cnn_model.fit(X_mrmr, y_train,epochs=10, verbose=0)   \n",
        "        _, accuracy = cnn_model.evaluate(X_test, y_test, return_dict=True)\n",
        "\n",
        "    else:\n",
        "        num_classes = 10\n",
        "        epochs = 20\n",
        "        cnn_model = Sequential([\n",
        "            Conv2D(filters=32,kernel_size=3,activation='relu', input_shape=(1, 40, 50),data_format='channels_first'),\n",
        "            MaxPooling2D(pool_size=2) ,\n",
        "            Dropout(0.2),\n",
        "            Flatten(), \n",
        "            Dense(32,activation='relu'),\n",
        "            Dense(10,activation = 'softmax')\n",
        "        ])\n",
        "        \n",
        "        cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        cnn_model.fit(X_train, y_train,epochs=10, verbose=0)   \n",
        "        _, accuracy = cnn_model.evaluate(X_test, y_test, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9A0FqFbkQ3u",
        "outputId": "8fed6b4b-62ee-4391-d80a-9cc15e5b1201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3172 - accuracy: 0.9231\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 1.0199 - accuracy: 0.6923\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.3431 - accuracy: 0.8462\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.5072 - accuracy: 0.8462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff59242d1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 109ms/step - loss: 0.4465 - accuracy: 0.9231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff59232bc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 112ms/step - loss: 0.5690 - accuracy: 0.6923\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.3549 - accuracy: 0.8462\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.4726 - accuracy: 0.7692\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.2798 - accuracy: 0.9231\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.6125 - accuracy: 0.6923\n"
          ]
        }
      ]
    }
  ]
}